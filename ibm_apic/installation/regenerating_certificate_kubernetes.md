## How to regenerate expired certificate for a kubernetes installation

### Problem
When you try to get the status of the pods with `kubectl get pods` you recieve the error message such as:

```
The connection to the server 10.x.x.x:6443 was refused - did you specify the right host or port?
```


### Cause
Client certificates generated by [kubeadm](https://kubernetes.io/docs/reference/setup-tools/kubeadm) expire after 1 year.  

Starting 11.7.1.1 (11.7.1 Fix Pack 1), Kubernetes certificates will auto-renew on upgrade due to a newer version of Kubernetes being built-in.


### Diagnostic

1- Check the kubelet logs using the command: <br>

 ```journalctl -u kubelet -f```

2- Verify if you see the entries in the log mentioning expired client certificate like:
```
Jan 08 02:42:25 <hostname> kubelet[5827]: I0108 02:42:25.868970    5827 server.go:407] Version: v1.13.10
Jan 08 02:42:25 <hostname> kubelet[5827]: I0108 02:42:25.869357    5827 plugins.go:103] No cloud provider specified.
Jan 08 02:42:25 <hostname> kubelet[5827]: E0108 02:42:25.872364    5827 bootstrap.go:209] Part of the existing bootstrap client certificate is expired: 2020-12-16 18:52:35 +0000 UTC
Jan 08 02:42:25 <hostname> kubelet[5827]: F0108 02:42:25.872492    5827 server.go:261] failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory
```
Then you need to renew the certificates following the step outlined below

### Resolution
#### _<u>Note</u>: The following steps were tested for Kubernetes version 1.13.10.<br> The steps may differ slightly if you have an older or newer version installed._

1. Impersonate root with <br>
`sudo su`

2. Stop the kubelet and Docker services with:<br>
`systemctl stop kubelet.service` <br>
`systemctl stop docker`

3. Change the directory with <br>
`cd /etc/kubernetes` <br>
This is the location of the default kubeconfig file to use when talking to the cluster. 

4. Renew the certificate with the command: <br> 
`kubeadm alpha certs renew all`<br>
  or <br>
`kubeadm alpha certs renew all --kubeconfig /etc/kubernetes/admin.conf` <br>

<u>Note</u>: <br>
_If the `--kubeconfig` flag is not set, a set of standard locations are searched for an existing
KubeConfig file (the default is `/etc/kubernetes/admin.conf`)._ 


5. Make a backup of the configuration like with <br>
   * `mv /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.bak`
   * `mv /etc/kubernetes/controller-manager.conf /etc/kubernetes/controller-manager.conf.bak`
   * `mv /etc/kubernetes/scheduler.conf /etc/kubernetes/scheduler.conf.bak`

6. Create all the required kubeconfig files calling the `all` subcommand `kubeadm init phase` <br>
 `kubeadm init phase kubeconfig all`

7. Restart the Kubelet and Docker services with <br>
 `systemctl start kubelet.service` <br>
 `systemctl start docker`


### Verifying the resolution
When issuing the command `kubectl version`, you should get the following output:
```
Client Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.10", GitCommit:"37d169313237cb4ceb2cc4bef300f2ae3053c1a2", GitTreeState:"clean", BuildDate:"2019-08-19T10:52:43Z", GoVersion:"go1.11.13", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.10", GitCommit:"37d169313237cb4ceb2cc4bef300f2ae3053c1a2", GitTreeState:"clean", BuildDate:"2019-08-19T10:44:49Z", GoVersion:"go1.11.13", Compiler:"gc", Platform:"linux/amd64"}
```

If you recieve the following message instead
```
Client Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.10", GitCommit:"37d169313237cb4ceb2cc4bef300f2ae3053c1a2", GitTreeState:"clean", BuildDate:"2019-08-19T10:52:43Z", GoVersion:"go1.11.13", Compiler:"gc", Platform:"linux/amd64"}
error: You must be logged in to the server (the server has asked for the client to provide credentials)
```

It usually means that you are not yet finished as the `admin.conf` in the directory `/etc/kubernetes` was not updated or recreated during the init phase.<br>

In that case you need to: <br>
1. Delete the existing config file with <br>
`rm /etc/kubernetes/admin.conf`
2. Run again the init phase command <br>
`kubeadm init phase kubeconfig all`<br>

This time you should see the following ouput: <br>
```
[kubeconfig] Writing "admin.conf" kubeconfig file
```

### Additional configuration ...
As you may not always login the machine as `root`, you may want to copy or update the newly recrecreated k8s configuration (`admin.config`) to the home directory of your user (eg `apicadm` in my case). <br>
This can be done with the command: <br>
`cat /etc/kubernetes/admin.conf > /home/apicadm/.kube/config`

Finally, to set as specific namespace (eg `dev`) as the default namespace, then edit the config file with the following steps: 
1. Launch the vi editor <br>
`vi /home/apicadm/.kube/config`
2. Enter in edit mode by pressing the `i` keyboard key
3. Add the `namespace:<namespace-name>` to the `context` section of the config file.

For example:
```
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
    namespace: dev
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
```
4. Exit the insert node by pressing the `esc` key
5. Save the file by typing `:wq!` and `enter`

You are now **back in business** and should be able to get the list of the pods with `kubectl get pods`.

### References

https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-alpha/
https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init-phase/
https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-certs/
https://www.ibm.com/support/pages/microservices-tier-apiserver-certificate-has-expired

<br>

<u>**NOTA BENE**</u>: <br>The steps outlined in this document were tested with the versions **2018.4.1.9** and **2018.4.1.13** of API Connect. Although they should be valid with all **v2018.4.1.x** versions, it was not tested with all of them.